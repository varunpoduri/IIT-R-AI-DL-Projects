{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load dataset (keep top 10,000 words)\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
        "\n",
        "# Remove top 20 most frequent words (indices 1-20 become 0)\n",
        "def filter_top_words(data):\n",
        "    return [[0 if word <= 20 else word for word in review] for review in data]\n",
        "\n",
        "x_train = filter_top_words(x_train)\n",
        "x_test = filter_top_words(x_test)\n",
        "\n",
        "# Pad sequences to a fixed length (500)\n",
        "maxlen = 500\n",
        "x_train_padded = pad_sequences(x_train, maxlen=maxlen, padding='post', truncating='post')\n",
        "x_test_padded = pad_sequences(x_test, maxlen=maxlen, padding='post', truncating='post')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SONO8ycaNya",
        "outputId": "d96b2e3d-b90c-452c-f23e-840675c530e2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    # Embedding layer (maps word indices to dense vectors)\n",
        "    Embedding(\n",
        "        input_dim=10001,  # Vocabulary size (0-10,000)\n",
        "        output_dim=128,   # Embedding dimension\n",
        "        input_length=maxlen,  # Input sequence length\n",
        "        mask_zero=True     # Ignore padding\n",
        "    ),\n",
        "    # SimpleRNN layer\n",
        "    SimpleRNN(64, activation='tanh'),\n",
        "    # Output layer (binary classification)\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sjrCXRZaRyX",
        "outputId": "8606ed3a-01d7-428a-8756-dc0c1479a5d7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    x_train_padded, y_train,\n",
        "    batch_size=128,\n",
        "    epochs=10,\n",
        "    validation_split=0.2  # 20% of training data for validation\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5bpmT_Pb2_a",
        "outputId": "057ad02f-825a-4eb8-a515-cba81027f61e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 3.0724e-04 - val_accuracy: 0.8462 - val_loss: 0.7337\n",
            "Epoch 2/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.3992e-04 - val_accuracy: 0.8450 - val_loss: 0.7479\n",
            "Epoch 3/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.0336e-04 - val_accuracy: 0.8462 - val_loss: 0.7608\n",
            "Epoch 4/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.6470e-04 - val_accuracy: 0.8482 - val_loss: 0.7740\n",
            "Epoch 5/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.3828e-04 - val_accuracy: 0.8464 - val_loss: 0.7848\n",
            "Epoch 6/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.1860e-04 - val_accuracy: 0.8470 - val_loss: 0.7959\n",
            "Epoch 7/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.0463e-04 - val_accuracy: 0.8468 - val_loss: 0.8065\n",
            "Epoch 8/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 9.1141e-05 - val_accuracy: 0.8488 - val_loss: 0.8170\n",
            "Epoch 9/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 7.6880e-05 - val_accuracy: 0.8464 - val_loss: 0.8264\n",
            "Epoch 10/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.7849e-05 - val_accuracy: 0.8484 - val_loss: 0.8361\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test set\n",
        "test_loss, test_acc = model.evaluate(x_test_padded, y_test)\n",
        "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWdb4-92b6xX",
        "outputId": "6f7e9e01-0f1f-4b84-ec6b-b9768893181c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.8391 - loss: 0.8478\n",
            "Test Accuracy: 83.96%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom review testing\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "def preprocess_review(review):\n",
        "    words = review.lower().split()\n",
        "    review_seq = [0 if word_index[word] <= 20 else word_index[word] for word in words if word in word_index and word_index[word] < 10000]\n",
        "    return pad_sequences([review_seq], maxlen=500)\n"
      ],
      "metadata": {
        "id": "Ed_aTDzEoV-M"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_review = \"This movie was a complete disappointment with poor acting, a predictable plot, and terrible dialogue. The pacing was slow, and the ending felt rushed. Not worth the time.\"\n",
        "preprocessed_review = preprocess_review(custom_review)\n",
        "prediction = model.predict(preprocessed_review)\n",
        "\n",
        "if prediction > 0.5:\n",
        "    print(\"Positive Sentiment\")\n",
        "else:\n",
        "    print(\"Negative Sentiment\")"
      ],
      "metadata": {
        "id": "X5EFuqJQ4Hhx",
        "outputId": "0dc5ea2e-5220-4161-c205-8ab2d8b8344b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Negative Sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input custom review\n",
        "custom_review =\"An absolute masterpiece with brilliant acting, a gripping plot, stunning visuals, and a powerful soundtrack. The story was captivating from start to finish. Truly a must-watch experience!\"\n",
        "preprocessed_review = preprocess_review(custom_review)\n",
        "prediction = model.predict(preprocessed_review)\n",
        "\n",
        "if prediction > 0.5:\n",
        "    print(\"Positive Sentiment\")\n",
        "else:\n",
        "    print(\"Negative Sentiment\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtSzkR5epbQN",
        "outputId": "7ad5a6f3-2db0-4402-832a-bf535ae6ed38"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Positive Sentiment\n"
          ]
        }
      ]
    }
  ]
}